{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction des fichier csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>...</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pxcmvdjn</td>\n",
       "      <td>xgwztkwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rucpziij</td>\n",
       "      <td>xtkaffoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>lrircsnp</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wxleyezf</td>\n",
       "      <td>emcorrxb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   respondent_id  h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "0              0           1.0             0.0                        0.0   \n",
       "1              1           3.0             2.0                        0.0   \n",
       "2              2           1.0             1.0                        0.0   \n",
       "3              3           1.0             1.0                        0.0   \n",
       "4              4           2.0             1.0                        0.0   \n",
       "\n",
       "   behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "0                   0.0                   0.0                    0.0   \n",
       "1                   1.0                   0.0                    1.0   \n",
       "2                   1.0                   0.0                    0.0   \n",
       "3                   1.0                   0.0                    1.0   \n",
       "4                   1.0                   0.0                    1.0   \n",
       "\n",
       "   behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "0                          0.0                      1.0   \n",
       "1                          0.0                      1.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          1.0                      0.0   \n",
       "4                          1.0                      0.0   \n",
       "\n",
       "   behavioral_touch_face  ...             income_poverty  marital_status  \\\n",
       "0                    1.0  ...              Below Poverty     Not Married   \n",
       "1                    1.0  ...              Below Poverty     Not Married   \n",
       "2                    0.0  ...  <= $75,000, Above Poverty     Not Married   \n",
       "3                    0.0  ...              Below Poverty     Not Married   \n",
       "4                    1.0  ...  <= $75,000, Above Poverty         Married   \n",
       "\n",
       "   rent_or_own   employment_status  hhs_geo_region                census_msa  \\\n",
       "0          Own  Not in Labor Force        oxchjgsf                   Non-MSA   \n",
       "1         Rent            Employed        bhuqouqj  MSA, Not Principle  City   \n",
       "2          Own            Employed        qufhixun  MSA, Not Principle  City   \n",
       "3         Rent  Not in Labor Force        lrircsnp       MSA, Principle City   \n",
       "4          Own            Employed        qufhixun  MSA, Not Principle  City   \n",
       "\n",
       "   household_adults  household_children  employment_industry  \\\n",
       "0               0.0                 0.0                  NaN   \n",
       "1               0.0                 0.0             pxcmvdjn   \n",
       "2               2.0                 0.0             rucpziij   \n",
       "3               0.0                 0.0                  NaN   \n",
       "4               1.0                 0.0             wxleyezf   \n",
       "\n",
       "   employment_occupation  \n",
       "0                    NaN  \n",
       "1               xgwztkwe  \n",
       "2               xtkaffoo  \n",
       "3                    NaN  \n",
       "4               emcorrxb  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train__set_features = pd.read_csv(\"training_set_features.csv\")\n",
    "test = pd.read_csv(\"test_set_features.csv\")\n",
    "train__set_features.shape\n",
    "\n",
    "train__set_labels = pd.read_csv(\"training_set_labels.csv\")\n",
    "\n",
    "y_h1n1 = train__set_labels['h1n1_vaccine']\n",
    "y_seasonal = train__set_labels['seasonal_vaccine']\n",
    "\n",
    "train__set_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train__set_features, y_h1n1, y_seasonal], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va gerer les valeurs manquantes et les valeurs categoriels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26708, 36) (26707, 38)\n"
     ]
    }
   ],
   "source": [
    "train.select_dtypes(include='object').isna().sum()\n",
    "\n",
    "\n",
    "# la moitié de employement _industry et _occupation est manquante \n",
    "train['employment_occupation'].value_counts()\n",
    "\n",
    "# essayer de creer catagorie big industrie // small industrie \n",
    "\n",
    "\n",
    "\n",
    "def employment_cat(X):\n",
    "    small_jobs = train['employment_occupation'].value_counts() < 500\n",
    "    small_industries = train['employment_industry'].value_counts() < 500\n",
    "    X.loc[X['employment_occupation'].isin(small_jobs.index[small_jobs]), 'employment_occupation'] = 'small_job'\n",
    "    X.loc[X['employment_industry'].isin(small_industries.index[small_industries]), 'employment_industry'] = 'small_industry'\n",
    "    return X \n",
    "\n",
    "train = employment_cat(train)\n",
    "test = employment_cat(test)\n",
    "\n",
    "print(test.shape, train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26708, 106) (26707, 84)\n"
     ]
    }
   ],
   "source": [
    "col = train.select_dtypes(exclude=(np.number)).columns\n",
    "\n",
    "train = pd.get_dummies(train, columns=col)\n",
    "test = pd.get_dummies(test, columns=col)\n",
    "\n",
    "print(test.shape, train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation des colonnes dans le cas ou la categorie n'était pas le test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26708, 106) (26707, 84)\n",
      "(26708, 108) (26707, 84)\n",
      "(26708, 108) (26707, 110)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape, train.shape)\n",
    "for col in train.columns: \n",
    "    if not(col in test.columns) and not(col in ['seasonal_vaccine', 'h1n1_vaccine']):\n",
    "        test[col] = pd.Series(np.zeros(test.shape[0]), name=col)\n",
    "print(test.shape, train.shape)\n",
    "\n",
    "for col in test.columns:\n",
    "    if not(col in train.columns):\n",
    "        train[col] = pd.Series(np.zeros(train.shape[0]), name=col)\n",
    "print(test.shape, train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation des valeurs manquantes grace aux KNN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# essayer d'utiliser le test set pour les NA\n",
    " \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "def manage_na(X,na_col): \n",
    "    X = X.copy()\n",
    "    numerical = X.select_dtypes(np.number)\n",
    "    non_na_columns = numerical.loc[:,numerical.isna().sum() == 0].columns\n",
    "    X_train = numerical.loc[numerical[na_col].isna() == False,non_na_columns]\n",
    "    y_train = numerical.loc[numerical[na_col].isna() == False,na_col]\n",
    "    X_na = numerical.loc[numerical[na_col].isna() == True, non_na_columns]\n",
    "    knn = KNeighborsRegressor()\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_na = knn.predict(X_na)\n",
    "    X.loc[X[na_col].isna() == True, na_col] = y_na\n",
    "    \n",
    "    return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = train.corr()['seasonal_vaccine'].apply(abs).sort_values() > 0.09\n",
    "\n",
    "nulls = train[cond.index[cond]].isna().sum() > 0\n",
    "\n",
    "\n",
    "for col in nulls[nulls == True].index:\n",
    "    train = manage_na(train, col)\n",
    "\n",
    "nulls_test = test.isna().sum() > 0\n",
    "\n",
    "for col in nulls_test[nulls_test == True].index:\n",
    "    test = manage_na(test, col)\n",
    "\n",
    "corr = train.corr()['seasonal_vaccine'].apply(abs).sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "respondent_id                  False\n",
       "h1n1_concern                   False\n",
       "h1n1_knowledge                 False\n",
       "behavioral_wash_hands          False\n",
       "behavioral_touch_face          False\n",
       "                               ...  \n",
       "behavioral_large_gatherings     True\n",
       "behavioral_avoidance            True\n",
       "household_adults                True\n",
       "opinion_h1n1_sick_from_vacc     True\n",
       "child_under_6_months            True\n",
       "Length: 110, dtype: bool"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls = train.isna().sum().sort_values() > 0\n",
    "nulls.sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "\n",
    "X = train\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": np.arange(7, 10,1), \n",
    "    \"max_depth\": np.arange(7, 10, 1),\n",
    "    \"min_samples_leaf\": np.arange(12,15 , 1), \n",
    "}\n",
    "grid = GridSearchCV(RandomForestRegressor(), params, cv=5)\n",
    "\n",
    "nulls = X.isna().sum() > 0 \n",
    "\n",
    "for col in nulls[nulls == True].index:\n",
    "    X = manage_na(X, col)\n",
    "\n",
    "\n",
    "X = X.drop([\"h1n1_vaccine\", \"seasonal_vaccine\"], axis=1).sort_index(axis=1)\n",
    "test = test.sort_index(axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test_seas = train_test_split(X, y_seasonal,  test_size=0.2, random_state=32,)\n",
    "\n",
    "#grid.fit(X_train, y_train)\n",
    "# grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26708, 108) (26707, 110)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(max_depth=9,min_samples_leaf=13, n_estimators=9)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_seasonal_predict = rf.predict(test)\n",
    "y_seasonal_predict_test = rf.predict(X_test)\n",
    "\n",
    "rf.score(X_test, y_test_seas)\n",
    "y_seasonal_predict.mean()\n",
    "y_seasonal_predict\n",
    "\n",
    "print(test.shape, train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.281321290665161\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test_h1n1 = train_test_split(X, y_h1n1,  test_size=0.2, random_state=32,)\n",
    "\n",
    "rf = RandomForestRegressor(max_depth=9,min_samples_leaf=12, n_estimators=9)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#grid.fit(X_train, y_train)\n",
    "#print(grid.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "y_h1n1_predict = rf.predict(test)\n",
    "y_h1n1_predict_test = rf.predict(X_test)\n",
    "\n",
    "\n",
    "print(rf.score(X_test, y_test_h1n1))\n",
    "y_h1n1_predict.mean()\n",
    "\n",
    "result = pd.concat([test[\"respondent_id\"], pd.Series(y_h1n1_predict, name=\"h1n1_vaccine\"), pd.Series(y_seasonal_predict, name=\"seasonal_vaccine\")], axis=1)\n",
    "result.to_csv(\"result_employment.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_format = pd.read_csv(\"submission_format.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8584447644662729"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "y_true = np.hstack([y_test_h1n1, y_test_seas])\n",
    "y_score = np.hstack([y_h1n1_predict_test, y_seasonal_predict_test])\n",
    "\n",
    "\n",
    "roc_auc_score(y_true, y_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
